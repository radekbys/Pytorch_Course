{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 15 10:40:59 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.02              Driver Version: 560.94         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080 Ti     On  |   00000000:01:00.0  On |                  N/A |\n",
      "| 47%   31C    P8             28W /  350W |     526MiB /  12288MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A        95      G   /Xwayland                                   N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#  checking if gpu acceleration works\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### introduction to Tensors\n",
    "\n",
    "# scalar\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  checking the dimensions number of a scalar\n",
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tensor back as Python item\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  checking the dimensions number\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tensor back as Python item, ->tensor with 2 elements cannot be converted to scalar\n",
    "# vector.item() -->gives an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape is diffrent than dimensions\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX\n",
    "MATRIX = torch.tensor([[7, 8], [9, 10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 10])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR\n",
    "TENSOR = torch.tensor([[[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Tensors:\n",
    "\n",
    "Random tensors are important because the way many neural networks lear is that\n",
    "they styart with tensor full of random numbers and then adjust those random numbers\n",
    "to better represent the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3268, 0.1921, 0.8592, 0.3402, 0.2386],\n",
       "        [0.4119, 0.8233, 0.3271, 0.9993, 0.3391],\n",
       "        [0.0251, 0.2895, 0.0277, 0.4045, 0.9290]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(3,5)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zeros and ones tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(size=(3, 4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(size=(3, 4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.range(0, 10) - deprecated\n",
    "one_to_ten = torch.arange(start=1, end=11, step=1)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tensors like\n",
    "ten_zeros = torch.zeros_like(one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor datatypes, one of 3 big errors you encounter in PyTorch & deep learning:\n",
    "1. Tensor not right datatype\n",
    "2. Tensor not right shape\n",
    "3. Tensors not right device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 4., 6.]) datatype=torch.float32\n"
     ]
    }
   ],
   "source": [
    "float_32_tensor = torch.tensor([3.0, 4.0, 6.0], \n",
    "                               dtype=None,              # What datatype is the tensor\n",
    "                               device=None,             # What device is your tensor on (cpu or cuda)\n",
    "                               requires_grad=False)     # Tracking gradients with this tensor operations\n",
    "print(float_32_tensor, f\"datatype={float_32_tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 4., 6.], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# changing tensor datatype\n",
    "new_tensor = float_32_tensor.type(torch.float16)\n",
    "print(new_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting information from tensor:\n",
    "1. tensor.dtype - getting datatype\n",
    "2. tensor.shape - getting tensors shape\n",
    "3. tensor.device - getting the device the tensor is running on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \n",
      "tensor datatype: torch.float32,\n",
      "tensor shape: torch.Size([3, 4]),\n",
      "tensor device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "some_tensor = torch.rand(3, 4)\n",
    "print(f\"\"\"  \n",
    "tensor datatype: {some_tensor.dtype},\n",
    "tensor shape: {some_tensor.shape},\n",
    "tensor device: {some_tensor.device}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor operations include:\n",
    "- Addition\n",
    "- Subtraction\n",
    "- Multiplication (element-wise)\n",
    "- Division\n",
    "- Matrix multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([1, 2, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.3000])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.3000])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.divide(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.subtract(tensor, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "\n",
      "X * X = tensor([[ 1,  4,  9],\n",
      "        [16, 25, 36],\n",
      "        [49, 64, 81]])\n",
      "\n",
      "Matrix multiplication:\n",
      " torch.matmul(X, X) = tensor([[ 30,  36,  42],\n",
      "        [ 66,  81,  96],\n",
      "        [102, 126, 150]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(f\"X = {X}\\n\")\n",
    "print(f\"X * X = {X*X}\\n\")\n",
    "print(f\"Matrix multiplication:\\n torch.matmul(X, X) = {torch.matmul(X, X)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 159 μs, sys: 7 μs, total: 166 μs\n",
      "Wall time: 124 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 30,  36,  42],\n",
       "        [ 66,  81,  96],\n",
       "        [102, 126, 150]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# how to get cpu time\n",
    "torch.matmul(X, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most common errors in deep learning is shape errors.\n",
    "\n",
    "1. The inner dimensions of tensors must mach\n",
    "- '(3, 2) @ (3, 2)' won't work\n",
    "- '(2, 3) @ (3, 2)' will work\n",
    "- '(3, 2) @ (2, 3)' will work\n",
    "\n",
    "2. The resulting matrix has the shape of outer dimensions\n",
    "- '(2, 3) @ (3, 2)' -> '(2, 2)'\n",
    "- '(3, 2) @ (2, 3)' -> '(3, 3)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '(3, 2) @ (3, 2)' won't work\n",
    "X = torch.rand(3, 2)\n",
    "Y = torch.rand(3, 2)\n",
    "# torch.matmul(X, Y) # RuntimeError: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0979, 1.1549, 0.9640],\n",
       "        [0.4420, 0.4433, 0.2709],\n",
       "        [1.2029, 1.2603, 1.0288]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# '(3, 2) @ (2, 3)' won't work\n",
    "X = torch.rand(3, 2)\n",
    "Y = torch.rand(2, 3)\n",
    "torch.matmul(X, Y) # works fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7938, 0.9720],\n",
       "        [1.3248, 1.1904]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# '(3, 2) @ (2, 3)' won't work\n",
    "X = torch.rand(2, 3)\n",
    "Y = torch.rand(3, 2)\n",
    "torch.matmul(X, Y) # works fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposition can be used like shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9630, 1.1275],\n",
       "        [0.5173, 0.7221]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(2, 3)\n",
    "Y = torch.rand(2, 3)\n",
    "torch.matmul(X, Y.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIN, MAX, MEAN, SUM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5030, 0.1451, 0.1400, 0.1288, 0.9200],\n",
       "        [0.5027, 0.0220, 0.8171, 0.9499, 0.1266],\n",
       "        [0.9426, 0.1065, 0.6636, 0.2829, 0.5365]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR = torch.rand(3, 5)\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum: (tensor(0.0220), tensor(0.0220))\n",
      "maximum: (tensor(0.9499), tensor(0.9499))\n",
      "mean: (tensor(0.4525), tensor(0.4525))\n",
      "sum: (tensor(6.7873), tensor(6.7873))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"minimum: {TENSOR.min(), torch.min(TENSOR)}\n",
    "maximum: {TENSOR.max(), torch.max(TENSOR)}\n",
    "mean: {TENSOR.mean(), torch.mean(TENSOR)}\n",
    "sum: {TENSOR.sum(), torch.sum(TENSOR)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index of min = 6\n",
      "index of max = 8\n"
     ]
    }
   ],
   "source": [
    "print(f\"index of min = {TENSOR.argmin()}\")\n",
    "print(f\"index of max = {TENSOR.argmax()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezing\n",
    "\n",
    "* Reshaping - reshape an input tensor to a defined shape\n",
    "* View - Return a view of an input tensor of as certain shape but keep the same memory as the original tensor\n",
    "* Stacking - combine multiple tensors on top of each other (horizontal and vertical stack)\n",
    "* Squeeze - removes all '1' dimensions from a tensor\n",
    "* Unsqueeze - add a '1' dimension to a target tensor\n",
    "* Permute - Return a view of the input with dimensions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1., 10.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Reshaping\n",
    "* total number of elements must match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_reshaped = x.reshape(1, 7) # RuntimeError: shape '[1, 7]' is invalid for input of size 9\n",
    "# x_reshaped = x.reshape(2, 9) # RuntimeError: shape '[2, 9]' is invalid for input of size 9\n",
    "x_reshaped = x.reshape(1, 9)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]),\n",
       " torch.Size([9, 1]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = x.reshape(9, 1)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.9519, 0.8204, 0.9867, 0.4527, 0.6964, 0.5625]), torch.Size([6]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand(6)\n",
    "y, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. View\n",
    "* Works like reshape, but output shares memory with the input, changing one affects the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y and its shape: (tensor([0.0000, 0.8204, 0.9867, 0.4527, 0.6964, 0.5625]), torch.Size([6]))\n",
      "z and its shape: (tensor([[0.0000, 0.8204, 0.9867],\n",
      "        [0.4527, 0.6964, 0.5625]]), torch.Size([2, 3]))\n"
     ]
    }
   ],
   "source": [
    "z = y.view(2, 3)\n",
    "z[0][0] = 0.0\n",
    "print(f\"y and its shape: {y, y.shape}\")\n",
    "print(f\"z and its shape: {z, z.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Stack\n",
    "* stasks the tensor along one of its dimensions, cannot use higher dimensions than what tensor has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [1., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " torch.Size([9]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked = torch.stack([x, x, x, x, x], dim=0)\n",
    "x_stacked, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1., 1.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [3., 3., 3., 3., 3.],\n",
       "         [4., 4., 4., 4., 4.],\n",
       "         [5., 5., 5., 5., 5.],\n",
       "         [6., 6., 6., 6., 6.],\n",
       "         [7., 7., 7., 7., 7.],\n",
       "         [8., 8., 8., 8., 8.],\n",
       "         [9., 9., 9., 9., 9.]]),\n",
       " torch.Size([9]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked = torch.stack([x, x, x, x, x], dim=1)\n",
    "x_stacked, x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[[0., 0.]],\n",
       " \n",
       "           [[0., 0.]]],\n",
       " \n",
       " \n",
       "          [[[0., 0.]],\n",
       " \n",
       "           [[0., 0.]]]]]),\n",
       " torch.Size([1, 2, 2, 1, 2]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(1, 2, 2, 1, 2)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0.],\n",
       "          [0., 0.]],\n",
       " \n",
       "         [[0., 0.],\n",
       "          [0., 0.]]]),\n",
       " torch.Size([2, 2, 2]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.squeeze()     # or torch.squeeze(x)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0., 0.],\n",
       "           [0., 0.]],\n",
       " \n",
       "          [[0., 0.],\n",
       "           [0., 0.]]]]),\n",
       " torch.Size([1, 2, 2, 2]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.unsqueeze(dim=0)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[[0., 0.]],\n",
       " \n",
       "           [[0., 0.]]],\n",
       " \n",
       " \n",
       "          [[[0., 0.]],\n",
       " \n",
       "           [[0., 0.]]]]]),\n",
       " torch.Size([1, 2, 2, 1, 2]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.unsqueeze(dim=-2)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Permute - rearanges the dimensions of a target tensor in a specific order\n",
    "* Input and output share memory like in view !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([480, 640, 3])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example image tensor\n",
    "IMAGE = torch.rand(480, 640, 3)\n",
    "IMAGE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 480, 640])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_PERMUTED = IMAGE.permute(2, 0, 1)\n",
    "IMAGE_PERMUTED.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_PERMUTED[0][0][0] = 1.0\n",
    "IMAGE[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_PERMUTED[2][479][639] = 1.0\n",
    "IMAGE[479][639][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0591e-01, 3.9826e-01, 4.2448e-01, 6.1355e-01, 8.1116e-02, 4.2014e-01,\n",
      "        5.8168e-01, 6.7445e-01, 8.3217e-01, 6.2294e-01, 6.3529e-01, 6.5074e-01,\n",
      "        7.8430e-01, 7.6170e-01, 4.7273e-01, 9.5904e-01, 3.0480e-01, 8.0973e-01,\n",
      "        1.9627e-01, 3.8789e-01, 3.7401e-01, 1.4615e-01, 5.0834e-01, 7.4194e-01,\n",
      "        6.4262e-01, 8.5811e-01, 5.2456e-01, 2.4709e-01, 6.6109e-01, 4.5582e-01,\n",
      "        6.6452e-01, 3.7271e-01, 6.9997e-01, 3.7955e-01, 4.7598e-01, 1.0049e-01,\n",
      "        3.5870e-01, 2.1851e-01, 4.4021e-01, 4.4045e-01, 6.2671e-01, 3.0792e-01,\n",
      "        8.9905e-01, 9.9817e-01, 8.8192e-01, 7.3421e-01, 8.2625e-01, 5.9338e-01,\n",
      "        9.7260e-01, 8.8012e-01, 6.2395e-01, 4.9621e-01, 5.9999e-01, 5.8098e-01,\n",
      "        5.2860e-01, 4.9689e-01, 2.2042e-01, 6.7091e-01, 2.1239e-01, 2.6579e-01,\n",
      "        7.3606e-01, 3.6749e-01, 2.0352e-01, 1.9526e-01, 7.9145e-01, 2.0738e-01,\n",
      "        9.9683e-01, 4.2802e-01, 5.2487e-02, 8.0118e-01, 3.9467e-01, 3.4634e-01,\n",
      "        1.0511e-01, 9.5215e-01, 7.8968e-02, 8.0244e-01, 8.3647e-01, 8.4470e-01,\n",
      "        1.6523e-01, 2.7433e-01, 7.1920e-01, 6.3114e-01, 1.7268e-03, 8.0541e-01,\n",
      "        1.3448e-01, 8.1837e-01, 8.0011e-01, 1.2141e-01, 2.6305e-01, 5.2715e-01,\n",
      "        1.8950e-01, 7.4183e-01, 1.9168e-02, 6.6712e-01, 7.8280e-01, 9.9912e-01,\n",
      "        7.4080e-01, 8.6765e-01, 2.5746e-01, 6.8658e-01, 7.4630e-01, 7.1258e-01,\n",
      "        9.5847e-01, 9.0312e-01, 1.8576e-01, 8.9851e-01, 2.2666e-01, 6.5658e-01,\n",
      "        5.6266e-01, 8.4542e-02, 4.3764e-01, 7.0790e-01, 5.7439e-01, 4.4034e-01,\n",
      "        4.4879e-01, 6.1382e-01, 8.9877e-01, 8.3399e-01, 5.9994e-02, 5.8645e-01,\n",
      "        7.2446e-01, 6.9078e-01, 6.1839e-01, 3.9439e-01, 8.1175e-01, 8.8344e-01,\n",
      "        2.6917e-01, 6.8115e-01, 1.6999e-01, 4.3141e-01, 5.0711e-01, 8.6306e-01,\n",
      "        4.1215e-01, 9.8037e-01, 5.3523e-01, 1.7658e-01, 7.6793e-01, 3.9730e-01,\n",
      "        1.4299e-02, 3.5211e-01, 9.3909e-01, 1.3395e-01, 8.1729e-01, 3.7284e-01,\n",
      "        3.5215e-01, 2.5002e-01, 7.6457e-01, 9.0913e-01, 9.7719e-01, 9.6910e-02,\n",
      "        4.9847e-02, 4.0726e-01, 8.2050e-01, 3.5823e-01, 2.7955e-01, 6.4192e-01,\n",
      "        2.3332e-01, 2.0932e-01, 8.4302e-01, 6.6886e-02, 7.0914e-02, 1.8113e-01,\n",
      "        1.2700e-01, 2.3200e-01, 7.9419e-01, 1.7863e-01, 1.9916e-03, 3.9037e-01,\n",
      "        8.3251e-02, 9.6352e-01, 4.4414e-01, 1.3111e-01, 2.7334e-01, 1.3424e-01,\n",
      "        4.4764e-01, 7.7638e-01, 2.1932e-01, 4.6808e-01, 8.6297e-01, 7.6549e-01,\n",
      "        7.8198e-01, 2.2041e-01, 8.9667e-01, 9.3889e-01, 3.6837e-01, 1.3336e-01,\n",
      "        9.4425e-01, 7.2157e-01, 9.1769e-01, 4.6328e-01, 1.6001e-01, 9.8947e-01,\n",
      "        3.4949e-01, 8.2187e-02, 1.8402e-01, 8.3684e-01, 2.2048e-01, 6.8891e-01,\n",
      "        5.8079e-01, 7.0396e-01, 3.7091e-01, 9.5796e-01, 2.4045e-01, 8.8017e-01,\n",
      "        8.9940e-01, 1.1125e-01, 5.4497e-01, 3.7030e-01, 2.5708e-01, 8.7861e-01,\n",
      "        2.5354e-01, 6.1306e-01, 1.7168e-01, 9.6939e-01, 6.2835e-01, 5.3821e-02,\n",
      "        1.8337e-01, 6.8402e-01, 9.5763e-01, 5.1658e-01, 6.1936e-02, 4.1824e-01,\n",
      "        8.6369e-01, 8.2898e-01, 8.6743e-01, 3.8914e-01, 9.4276e-01, 8.4708e-01,\n",
      "        8.0392e-01, 6.3041e-01, 3.6383e-01, 3.3991e-01, 4.1249e-01, 9.2816e-03,\n",
      "        2.0041e-01, 3.9095e-01, 6.8260e-01, 9.3651e-01, 7.3453e-01, 4.0239e-01,\n",
      "        2.7494e-01, 5.8680e-01, 2.7022e-01, 7.8292e-01, 5.7943e-01, 8.1462e-01,\n",
      "        4.9438e-01, 1.0870e-01, 8.0363e-01, 6.3413e-02, 4.0105e-01, 1.5451e-01,\n",
      "        8.5881e-01, 3.8466e-01, 7.0837e-02, 1.5763e-01, 8.2441e-01, 1.1026e-01,\n",
      "        6.2967e-01, 8.1766e-01, 9.3749e-02, 8.5114e-01, 4.2954e-01, 4.9326e-01,\n",
      "        1.3292e-01, 9.2980e-01, 1.0549e-01, 2.0951e-01, 9.9060e-01, 9.8699e-01,\n",
      "        6.2908e-02, 8.2923e-01, 9.2295e-01, 3.6497e-01, 7.2587e-02, 6.1558e-01,\n",
      "        5.2288e-01, 2.9915e-02, 8.1380e-01, 3.3934e-01, 7.8128e-01, 3.8862e-01,\n",
      "        4.3406e-01, 1.1919e-01, 8.9344e-01, 2.4487e-01, 8.0381e-02, 1.4558e-02,\n",
      "        5.0907e-01, 4.4951e-01, 1.5530e-01, 7.0822e-01, 2.0532e-01, 8.4417e-01,\n",
      "        7.5562e-01, 3.7754e-02, 9.7600e-01, 8.8042e-02, 6.5526e-01, 6.5753e-01,\n",
      "        5.8084e-01, 1.0451e-01, 2.1135e-01, 5.1632e-01, 7.7620e-01, 2.2001e-01,\n",
      "        7.5189e-01, 3.1405e-01, 2.2993e-01, 3.2618e-01, 1.7500e-01, 8.7801e-01,\n",
      "        8.7637e-01, 4.0989e-01, 1.4939e-01, 1.5639e-01, 9.7613e-01, 1.3616e-01,\n",
      "        1.9085e-01, 5.9541e-01, 3.9272e-01, 4.0743e-01, 3.3697e-01, 3.2041e-01,\n",
      "        3.6788e-01, 6.6292e-01, 3.2547e-01, 4.8209e-01, 5.5351e-01, 5.2317e-01,\n",
      "        1.6642e-01, 9.1109e-01, 3.3958e-02, 1.5480e-01, 7.7786e-01, 8.2521e-01,\n",
      "        4.7387e-01, 2.3980e-01, 2.6510e-01, 1.0567e-01, 2.3530e-01, 1.2801e-01,\n",
      "        4.3751e-01, 7.5975e-01, 9.0560e-02, 6.9256e-02, 3.3977e-01, 4.8573e-01,\n",
      "        7.7844e-01, 5.4684e-01, 9.2374e-02, 2.0994e-01, 2.9502e-01, 5.7761e-01,\n",
      "        5.9929e-03, 2.6501e-01, 9.8764e-01, 9.4900e-01, 4.8003e-02, 9.0969e-01,\n",
      "        3.8372e-01, 6.0692e-01, 5.7722e-02, 3.6979e-01, 5.4728e-01, 4.7875e-01,\n",
      "        5.4269e-02, 8.1021e-01, 3.8282e-01, 3.4750e-01, 4.5395e-01, 1.9260e-01,\n",
      "        3.9178e-03, 6.4596e-01, 9.7393e-01, 1.5819e-01, 8.3764e-01, 8.7351e-01,\n",
      "        4.5756e-01, 8.6124e-01, 5.0690e-01, 5.7411e-02, 1.1165e-01, 1.3924e-01,\n",
      "        5.4635e-01, 6.0927e-01, 7.4706e-01, 9.2117e-01, 2.0460e-01, 2.3948e-02,\n",
      "        9.9399e-01, 7.4058e-01, 1.3545e-01, 1.8753e-01, 4.3504e-01, 1.2679e-01,\n",
      "        3.0676e-01, 6.2037e-01, 5.1989e-02, 5.6699e-01, 2.2483e-01, 5.3882e-01,\n",
      "        8.5027e-01, 1.9560e-01, 4.8894e-01, 2.7708e-01, 2.0627e-01, 4.0901e-01,\n",
      "        7.1981e-01, 9.9897e-01, 3.4798e-01, 8.5260e-01, 3.7077e-01, 7.3751e-01,\n",
      "        6.7015e-01, 6.0866e-01, 9.0531e-01, 5.7071e-01, 6.5751e-01, 8.7709e-01,\n",
      "        6.8354e-01, 9.6848e-01, 4.1097e-02, 6.3208e-01, 4.4948e-01, 4.3410e-01,\n",
      "        4.3658e-01, 9.6586e-01, 6.4741e-01, 9.4518e-01, 2.1875e-01, 1.8717e-01,\n",
      "        2.6262e-02, 5.5509e-01, 5.1536e-01, 5.5513e-01, 9.8047e-01, 5.8623e-01,\n",
      "        2.3140e-01, 3.4633e-01, 1.4900e-02, 7.3714e-01, 7.6410e-01, 1.9065e-01,\n",
      "        9.6146e-01, 7.1131e-01, 8.8033e-01, 3.8125e-01, 1.9639e-03, 9.1374e-01,\n",
      "        5.2779e-01, 7.4216e-01, 7.3405e-02, 3.7267e-01, 4.3464e-02, 5.1930e-01,\n",
      "        2.8821e-01, 6.5369e-01, 2.2726e-01, 4.5138e-01, 8.9714e-01, 5.8351e-01,\n",
      "        9.4835e-01, 9.8569e-01, 6.1369e-01, 3.0568e-02, 5.9200e-01, 4.7203e-01,\n",
      "        2.5351e-01, 9.6185e-01, 5.5756e-01, 9.1657e-01, 9.2802e-01, 1.6185e-01,\n",
      "        4.5106e-01, 5.7387e-01, 7.5156e-01, 4.7146e-01, 7.5320e-01, 1.6296e-01,\n",
      "        9.6535e-02, 7.4691e-01, 1.3705e-01, 5.7571e-01, 2.1697e-01, 3.9758e-01,\n",
      "        2.7781e-01, 1.9764e-01, 4.8259e-01, 2.2757e-01, 3.8510e-01, 1.0862e-01,\n",
      "        7.4367e-01, 2.3354e-01, 8.8356e-01, 1.9241e-01, 1.5585e-01, 7.0350e-01,\n",
      "        4.5678e-01, 7.1397e-01, 1.4689e-01, 7.9419e-01, 3.7274e-01, 3.2058e-01,\n",
      "        3.9348e-02, 2.4508e-01, 4.9160e-01, 5.7443e-01, 6.1490e-01, 7.7899e-01,\n",
      "        9.4192e-01, 4.7690e-02, 6.6265e-01, 7.1096e-01, 6.3013e-01, 7.0886e-01,\n",
      "        2.6009e-01, 5.9927e-01, 3.2940e-01, 4.9807e-01, 3.3758e-01, 3.7704e-01,\n",
      "        3.8101e-01, 4.8251e-01, 5.7222e-01, 3.9091e-01, 9.3830e-01, 8.1632e-01,\n",
      "        4.0528e-01, 1.8951e-01, 8.6372e-01, 3.6358e-01, 5.5573e-01, 3.0012e-01,\n",
      "        5.7137e-01, 5.3872e-01, 3.4466e-01, 5.7787e-01, 8.4057e-01, 8.8731e-02,\n",
      "        1.6787e-01, 3.6098e-01, 9.9522e-01, 4.9404e-01, 1.9161e-01, 8.2411e-01,\n",
      "        1.3816e-02, 8.7658e-01, 2.1896e-01, 4.8819e-01, 2.0551e-01, 2.9800e-01,\n",
      "        5.1731e-01, 5.1937e-01, 6.9810e-01, 5.7403e-01, 8.9658e-01, 2.4269e-01,\n",
      "        9.5953e-01, 1.9587e-01, 7.6406e-01, 1.4842e-01, 9.8778e-01, 8.4643e-01,\n",
      "        1.8688e-01, 5.0849e-01, 7.3863e-01, 2.3706e-01, 5.0707e-01, 1.5459e-01,\n",
      "        9.2541e-01, 9.9990e-01, 9.3042e-01, 9.3351e-02, 9.2931e-01, 6.7440e-01,\n",
      "        1.0929e-01, 4.8703e-01, 6.6516e-01, 8.0328e-01, 6.8235e-02, 7.9610e-01,\n",
      "        5.9614e-01, 3.9164e-01, 9.2188e-01, 2.7204e-01, 5.2335e-01, 3.3500e-01,\n",
      "        2.9771e-01, 9.7049e-01, 7.6622e-01, 6.3472e-01, 2.4310e-01, 3.0543e-01,\n",
      "        2.0537e-01, 2.7740e-01, 2.9310e-01, 2.9003e-01, 5.0017e-01, 2.5639e-02,\n",
      "        1.7397e-01, 2.7117e-01, 5.9021e-01, 4.8453e-01, 5.5772e-01, 4.0263e-01,\n",
      "        5.7647e-01, 7.3529e-01, 4.1095e-01, 8.1181e-01, 1.1911e-01, 3.4221e-01,\n",
      "        5.6993e-02, 7.9298e-04, 2.7188e-01, 2.2295e-01, 9.7476e-01, 5.4821e-01,\n",
      "        9.0419e-01, 8.5859e-02, 3.7957e-01, 6.0957e-01, 9.8898e-01, 4.0098e-01,\n",
      "        7.9575e-01, 9.3110e-01, 6.4984e-01, 2.5105e-01, 4.8380e-01, 7.1170e-01,\n",
      "        2.9030e-01, 7.6234e-01, 2.9136e-02, 8.9583e-01, 9.1000e-01, 5.0940e-01,\n",
      "        8.8557e-02, 9.9380e-01, 5.6271e-01, 4.1612e-01])\n"
     ]
    }
   ],
   "source": [
    "print(IMAGE_PERMUTED[0][:][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch and NumPy\n",
    "\n",
    "* default dtype when converting from numpy array to tensor is float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array = [0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n",
      "tensor = tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=torch.float64)\n",
      "tensor_f32 = tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "numpy_tensor = [0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy\n",
    "\n",
    "array = numpy.arange(0.0, 10.0)\n",
    "print(f\"array = {array}\")\n",
    "tensor = torch.from_numpy(array)\n",
    "print(f\"tensor = {tensor}\")\n",
    "tensor_f32 = torch.from_numpy(array).type(torch.float32)\n",
    "print(f\"tensor_f32 = {tensor_f32}\")\n",
    "numpy_tensor = tensor_f32.numpy()\n",
    "print(f\"numpy_tensor = {numpy_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility\n",
    "To increase reproducibility random seed is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.8823, 0.6990, 0.6192]),\n",
       " tensor([0.4137, 0.0534, 0.8001]),\n",
       " tensor([0.7998, 0.0751, 0.6847]),\n",
       " tensor([0.6603, 0.3539, 0.8063]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(3), torch.rand(3), torch.rand(3), torch.rand(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "MATRIX1 = torch.rand(3, 4)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "MATRIX2 = torch.rand(3, 4)\n",
    "MATRIX1 == MATRIX2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 15 10:22:28 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.02              Driver Version: 560.94         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080 Ti     On  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   49C    P8             31W /  350W |     335MiB /  12288MiB |      8%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    " # Checking GPU\n",
    " !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking access with pytorch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device Agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting tensors (and models) on a GPU\n",
    "(NumPy works only on cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor (default on the CPU)\n",
    "tensor = torch.rand(2, 2)\n",
    "tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Moving tensor to GPU (if aviable)\n",
    "tensor = tensor.to(device)\n",
    "tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.86940444, 0.5677153 ],\n",
       "       [0.74109405, 0.4294045 ]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor.numpy() #TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n",
    "numpy_array = tensor.cpu().numpy()\n",
    "numpy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8694, 0.5677],\n",
       "        [0.7411, 0.4294]], device='cuda:0')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# back to GPU\n",
    "tensor = torch.from_numpy(numpy_array).to(device)\n",
    "tensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
